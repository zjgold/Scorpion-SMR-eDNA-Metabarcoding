"0","#Metadata Upload"
"0","input_meta_path <- ""../data/calcofi_metadata_edited_06222020.txt"" "
"0","metadata <- read.table(input_meta_path, header = 1, sep = ""\t"", stringsAsFactors = F)"
"0","metadata %>% "
"0","unite(., col = sample2, c(""Location"", ""ext_rep"",""tech_rep""), remove = FALSE) %>% #needed for matching to ASV Table"
"0","  mutate( sample_new = if_else(is.na(Location), sample,sample2)) ->metadata"
"0","#Hash.Key Upload"
"0","input_hash_path <- ""../data/Hashes_20201026.txt"""
"0","Hash.key <- read.table(input_hash_path, header = 1, sep = ""\t"", stringsAsFactors = F)"
"0","#Reupload Data"
"0","ASV.nested <- readRDS(file =""../data/ASV.nested_final.RDS"")"
"0","ASV.summary <- readRDS(file =""../data/ASV.summary_final.RDS"")"
"0","ASV.nested$Step4.tibble[[1]]  %>%  dplyr::select(Hash) %>%  unique() %>% dim()"
"1","[1]"
"1"," 973"
"1","   1"
"1","
"
"0","#973"
"0","ASV.nested$Step4.tibble[[2]]  %>%  dplyr::select(Hash) %>%  unique() %>% dim()"
"1","[1]"
"1"," 957"
"1","   1"
"1","
"
"0","#957"
"0","ASV.nested$Step4.tibble[[1]]  %>% summarise(sum(nReads))"
"1"," "
"1"," sum(nReads)"
"1","
1"
"1","    55079895"
"1","
"
"0","#55079895"
"0","ASV.nested$Step4.tibble[[2]]  %>% summarise(sum(nReads))"
"1"," "
"1"," sum(nReads)"
"1","
1"
"1","    55220488"
"1","
"
"0","#55220488"
"0","55220488 +55079895"
"1","[1]"
"1"," 110300383"
"1","
"
