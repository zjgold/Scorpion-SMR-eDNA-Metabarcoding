Tech_rep2=Tech_rep,
Miseq_run2=Miseq_run) %>%
dplyr::select(Var1,Var2,Site1,Miseq_run1,Bio_rep1,Tech_rep1,Miseq_run2,Site2,Bio_rep2,Tech_rep2,value) %>%
unite( Site1, Bio_rep1, col= "station1", remove=F) %>%
unite( Site2, Bio_rep2, col= "station2", remove=F) %>%
unite( Miseq_run1, station1, col= "typers1", remove=F) %>%
unite( Miseq_run2, station2, col= "typers2", remove=F) %>%
unite( Miseq_run1, Site1, col= "type_site1", remove=F) %>%
unite( Miseq_run2, Site2, col= "type_site2", remove=F) %>%
ungroup() %>%
mutate(Distance.type = case_when(typers1 == typers2 ~ "PCR.replicates",
type_site1 == type_site2 ~ "Biol.replicates",
Miseq_run1 == Miseq_run2 ~ "Same Barcode Different Site",
TRUE ~ "Different Barcode")) %>%
dplyr::select(Sample1 = Var1, Sample2 = Var2 , value , Distance.type) %>%
filter (Sample1 != Sample2) -> all.distances.to.plot.post
# Checking all went well
sapply(all.distances.to.plot.post, function(x) summary(is.na(x)))
all.distances.to.plot.post$Distance.type <- all.distances.to.plot.post$Distance.type  %>% fct_relevel( "PCR.replicates", "Biol.replicates", "Same Barcode Different Site", "Different Barcode")
plot_6 <- ggplot (all.distances.to.plot.post , aes (fill = Distance.type, x = value,after_stat(density))) +
geom_histogram(stat = 'bin', alpha = 0.9, binwidth = 0.05) + #xlim(0, 1) +
facet_wrap( ~ Distance.type) +
labs (x = "Pairwise Dissimilarity", y = "Density" ,
fill = "Groups", title = "eDNA Pairwise Dissimilarity Between Samples", subtitle = "Post Site Occupancy") +theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank())
ggsave(plot=plot_6,here("decontam","Output_plots","eDNA_Pairwise_Dissimilarity_Between_Samples_post_occupancy.png"), device = "png", width = 12, height = 8, units = "in")
#Need to Remove Single Sampels
cleaned.tibble.post_occ  %>%
group_by(Miseq_run,Site,Bio_rep) %>%
dplyr::summarise(cases = n_distinct(Tech_rep)) %>%
filter(., cases == 1) %>%
unite(col="location_id", Miseq_run,Site,Bio_rep, remove = FALSE, sep=":") %>% ungroup() %>%
dplyr::select(location_id) -> singles
#Currently this method does not filter out these single tech reps. There are only 3
#Nest Data
cleaned.tibble.post_occ  %>%
unite(col="location_id", Miseq_run,Site,Bio_rep, remove = FALSE, sep=":") %>%
filter(., !location_id %in% singles$location_id) %>%
group_by(location_id) %>% nest() -> nested.cleaning
nested.cleaning %>%
mutate(matrix = map(data, tibble_to_vegdist_bio_rep)) -> nested.cleaning
# Convert
nested.cleaning %>% mutate(ncomparisons = map(matrix, length)) -> nested.cleaning
#Calculate distances to centroid
nested.cleaning <- nested.cleaning %>% mutate(distances = map2(matrix, location_id, dist_to_centroid))
nested.cleaning %>%
separate(location_id, c("Miseq_run","Site","Bio_rep"), sep=":") %>%
unnest_longer(distances) %>%
dplyr::select(Miseq_run,Site,Bio_rep, distances_id,distances) -> all_distances.groups #unnest data
normparams.step5 <- MASS::fitdistr(all_distances.groups$distances, "normal")$estimate
#Calculate Probability
probs.step5 <- pnorm(all_distances.groups$distances, normparams.step5[1], normparams.step5[2])
#Determine Outliers
outliers.step5 <- which(probs.step5>max_dist_probability_cutoff)
#Remove Outliers
discard.step5 <-names(all_distances.groups$distances[outliers.step5])
to_write_discarded.step5 <- tibble(distances_id = discard.step5,
distance = all_distances.groups$distances[outliers.step5])
to_write_discarded.step5 <- to_write_discarded.step5 %>% left_join(tibble(distances_id = discard.step5,
probs = probs.step5[outliers.step5]))
write_csv(to_write_discarded.step5 ,here("decontam","step5.discared_samples.csv"))
cleaned.tibble.post_occ %>%
unite(col="distances_id", Miseq_run,Site,Bio_rep,Tech_rep, remove = FALSE, sep=":") ->cleaned.tibble.post_occ_for_plotting
all_distances.groups %>%
dplyr::select(-Miseq_run,-Site,-Bio_rep) -> all_distances.groups_for_plotting
cleaned.tibble.post_occ_for_plotting %>%
filter(., !distances_id %in% discard.step5) %>%
dplyr::group_by(Miseq_run,Site,Bio_rep) %>%
dplyr::summarise(cases = n_distinct(distances_id)) %>%
filter(., Site !="Taylor") %>%
ggplot()+
geom_raster(aes(x= Site, y = Bio_rep, fill = cases))+
geom_text(aes(x= Site, y = Bio_rep, label = cases),color="white") +
ggtitle("Sample Replication Level") +facet_wrap(~Miseq_run) +
theme(axis.text.x = element_text(angle = 90))-> plot_7
ggsave(plot=plot_7,here("decontam","Output_plots","Final_sample_replication_level.png"), device = "png", width = 20, height = 8, units = "in")
ASV.nested %>%
mutate (Step4.tibble_edited = purrr::map(Step4.tibble,
function(.x){
.x %>%
mutate(., Miseq_run= str_detect(seq_number,barcode_1)) %>%
left_join(metadata, by=c("sample"="New_name")) %>%
unite(col="distances_id", Miseq_run,Site,Bio_rep, remove = FALSE, sep=":")
}) ) -> ASV.nested
#Filter Sample
ASV.nested %>%
mutate(Step5.tibble = purrr::map (Step4.tibble_edited,  ~ filter(.,! distances_id %in% to_write_discarded.step5$distances_id))) -> ASV.nested
ASV.nested %>%
transmute(Miseq_run, Summary.1 = purrr::map(Step5.tibble, ~ how.many(ASVtable = .,round ="5.Dissimilarity"))) %>%
left_join(ASV.summary) %>%
mutate(Summary   = map2(Summary, Summary.1, bind_rows)) %>%
dplyr::select(-Summary.1) -> ASV.summary
ASV.summary$Summary
saveRDS(ASV.nested,file=here("decontam","ASV.nested_final.RDS"))
saveRDS(ASV.summary,file=here("decontam","ASV.summary_final.RDS"))
ASV.nested <- readRDS(file=here("decontam","ASV.nested_final.RDS"))
ASV.summary <- readRDS(file=here("decontam","ASV.summary_final.RDS"))
hash.key %>%
distinct(.,sum.taxonomy) -> hashes_unique
hashes_unique$number <- row.names(hashes_unique)
hashes_unique$number <- paste0("taxon_",hashes_unique$number)
row.names(hashes_unique)<-hashes_unique$number
hash.key %>%
left_join(hashes_unique, by="sum.taxonomy") -> hash.key.updated
hash.key.updated$number %>% unique() -> total_taxa
ASV.nested$Step3.tibble[[1]] %>%
mutate(miseq = ASV.nested$Miseq_run[[1]]) %>%
unite(miseq,sample, col="Sample") %>%
left_join(hash.key.updated) %>%
dplyr::group_by(number,Sample) %>%
dplyr::summarise(nReads=sum(nReads)) %>%
spread(., Sample, nReads) %>% #convert to wide data format
replace(is.na(.), 0) -> barcode_1_pre_df
barcode_1_pre_df$number %>%  unique() -> barcode_1_pre_df_taxa
total_kept_taxa <- (barcode_1_pre_df_taxa) %>% unique()
if (rlang::is_empty(setdiff(total_kept_taxa,barcode_1_pre_df_taxa))) {
barcode_1_pre_df %>% ungroup() %>%
arrange(number) -> barcode_1_pre_df
} else {
barcode_1_pre_df %>% ungroup() %>%
add_row(number=setdiff(total_kept_taxa,barcode_1_pre_df_taxa)) %>%
arrange(number) %>%
replace(is.na(.), 0) -> barcode_1_pre_df
}
barcode_1_pre_df <- as.data.frame(barcode_1_pre_df)
row.names(barcode_1_pre_df) <- barcode_1_pre_df$number
barcode_1_pre_df %>% ungroup() %>% dplyr::select(-number) -> barcode_1_pre_df
####First, we want to create proportions by dividing by the rowsums:
####we could do this with sweep() or mutate_all() or other ways, but using vegan:
barcode_1_prop <- decostand(barcode_1_pre_df, method = "total", MARGIN = 2)
####Second, we want to ask how the proprortion for each species has changed across columns (samples).
####We do this by scaling everything to the max observed in each row.
####to do this WITHIN a dataset, we could just do (again, using vegan):
barcode_1_prop_index <- decostand(barcode_1_prop, method = "max", MARGIN = 1)
####This gives us an index between 0 and 1 for each species in each dataset.
####But if we want to combine datasets, this second step has to happen in the combined dataset, so it all gets scaled to 0-1.
####easy enough:
combined_index <- decostand(cbind(barcode_1_prop), method = "max", MARGIN = 1)
####How both datasets are combined, on a common, comparable scale.
### Output Read Count Data
pre_results_reads = cbind(barcode_1_prop)
hash.key.updated.2 <- hash.key.updated[!duplicated(hash.key.updated$number), ]
pre_results_reads$number <- rownames(pre_results_reads)
pre_results_reads %>%
left_join(hash.key.updated.2, by="number") %>%
dplyr::select(-number,-seq_number) -> pre_results_reads
saveRDS(pre_results_reads,file=here("decontam","Output_R","pre_occupancy_results_sum.taxonomy_tech_reps_separate_read_counts.RDS"))
write_csv(pre_results_reads ,here("decontam","Output_csv","pre_occupancy_results_sum.taxonomy_tech_reps_separate_read_counts.csv"))
combined_index$number <- rownames(combined_index)
combined_index %>%
left_join(hash.key.updated.2, by="number") %>%
dplyr::select(-number,-seq_number) -> combined_index
saveRDS(combined_index,file=here("decontam","Output_R","pre_occupancy_results_sum.taxonomy_tech_reps_separate_eDNA_index.RDS"))
write_csv(combined_index ,here("decontam","Output_csv","pre_occupancy_results_sum.taxonomy_tech_reps_separate_eDNA_index.csv"))
hash.key.updated$number %>% unique() -> total_taxa
ASV.nested$Step5.tibble[[1]] %>%
mutate(miseq = ASV.nested$Miseq_run[[1]]) %>%
unite(miseq,sample, col="Sample") %>%
left_join(hash.key.updated) %>%
dplyr::group_by(number,Sample) %>%
dplyr::summarise(nReads=sum(nReads)) %>%
spread(., Sample, nReads) %>% #convert to wide data format
replace(is.na(.), 0) -> barcode_1_post_occ_df
barcode_1_post_occ_df$number %>%  unique() -> barcode_1_post_occ_df_taxa
total_kept_taxa <- barcode_1_post_occ_df_taxa %>% unique()
if (rlang::is_empty(setdiff(total_kept_taxa,barcode_1_post_occ_df_taxa))) {
barcode_1_post_occ_df %>% ungroup() %>%
arrange(number) -> barcode_1_post_occ_df
} else {
barcode_1_post_occ_df %>% ungroup() %>%
add_row(number=setdiff(total_kept_taxa,barcode_1_post_occ_df_taxa)) %>%
arrange(number) %>%
replace(is.na(.), 0) -> barcode_1_post_occ_df
}
barcode_1_post_occ_df <- as.data.frame(barcode_1_post_occ_df)
row.names(barcode_1_post_occ_df) <- barcode_1_post_occ_df$number
barcode_1_post_occ_df %>% ungroup() %>% dplyr::select(-number) -> barcode_1_post_occ_df
####first, we want to create proportions by dividing by the rowsums:
####we could do this with sweep() or mutate_all() or other ways, but using vegan:
barcode_1_post_occ_df_prop <- decostand(barcode_1_post_occ_df, method = "total", MARGIN = 2)
####Second, we want to ask how the proprortion for each species has changed across columns (samples).
####We do this by scaling everything to the max observed in each row.
####to do this WITHIN a dataset, we could just do (again, using vegan):
barcode_1_post_occ_df_index <- decostand(barcode_1_post_occ_df_prop, method = "max", MARGIN = 1)
####this gives us an index between 0 and 1 for each species in each dataset.
####But if we want to combine datasets, this second step has to happen in the combined dataset, so it all gets scaled to 0-1.
####easy enough:
combined_index <- decostand(cbind(barcode_1_post_occ_df_index), method = "max", MARGIN = 1)
####now both datasets are combined, on a common, comparable scale.
### Output Post Occupancy Read Data
results_post_occ_reads = cbind(barcode_1_post_occ_df)
hash.key.updated.2 <- hash.key.updated[!duplicated(hash.key.updated$number), ]
results_post_occ_reads$number <- rownames(results_post_occ_reads)
results_post_occ_reads %>%
left_join(hash.key.updated.2, by="number") %>%
dplyr::select(-number,-seq_number) -> results_post_occ_reads
saveRDS(results_post_occ_reads,file=here("decontam","Output_R","post_occupancy_results_sum.taxonomy_tech_reps_separate_read_counts.RDS"))
write_csv(results_post_occ_reads ,here("decontam","Output_csv","post_occupancy_results_sum.taxonomy_tech_reps_separate_read_counts.csv"))
combined_index$number <- rownames(combined_index)
combined_index %>%
left_join(hash.key.updated.2, by="number") %>%
dplyr::select(-number,-seq_number) -> combined_index
saveRDS(combined_index,file=here("decontam","Output_R","post_occupancy_results_sum.taxonomy_tech_reps_separate_eDNA_index.RDS"))
write_csv(combined_index ,here("decontam","Output_csv","post_occupancy_results_sum.taxonomy_tech_reps_separate_eDNA_index.csv"))
ASV.nested$Step3.tibble[[1]] %>%
mutate(Sample = sample) %>%
left_join(hash.key.updated) %>%
dplyr::group_by(number,Sample) %>%
dplyr::summarise(nReads=sum(nReads)) %>%
spread(., Sample, nReads) %>% #convert to wide data format
replace(is.na(.), 0)  -> barcode_1_pre_df
barcode_1_pre_df$number %>%  unique() -> barcode_1_pre_df_taxa
metadata %>%
filter(., !(New_name %in% controls)) %>%
filter(.,!(New_name %in% colnames(barcode_1_pre_df))) %>%
pull(New_name) %>%  unique()-> columns2add
barcode_1_pre_df <- as.data.frame(barcode_1_pre_df)
barcode_1_pre_df %>%
tibble::add_column(!!!set_names(as.list(rep(NA, length(columns2add))),nm=columns2add)) %>%
replace(is.na(.), 0) %>%
dplyr::select(sort(tidyselect::peek_vars()))-> barcode_1_pre_df
row.names(barcode_1_pre_df) <- barcode_1_pre_df$number
barcode_1_pre_df %>% ungroup() -> barcode_1_pre_df
total_kept_taxa <- barcode_1_pre_df_taxa %>% unique()
if (rlang::is_empty(setdiff(total_kept_taxa,barcode_1_pre_df_taxa))) {
barcode_1_pre_df %>% ungroup() %>%
arrange(number) -> barcode_1_pre_df
} else {
barcode_1_pre_df %>% ungroup() %>%
add_row(number=setdiff(total_kept_taxa,barcode_1_pre_df_taxa)) %>%
arrange(number) %>%
replace(is.na(.), 0) -> barcode_1_pre_df
}
barcode_1_pre_df <- as.data.frame(barcode_1_pre_df)
row.names(barcode_1_pre_df) <- barcode_1_pre_df$number
barcode_1_pre_df %>% ungroup() %>% dplyr::select(-number) -> barcode_1_pre_df
barcode_1_pre_df-> combined_df
####First, we want to create proportions by dividing by the rowsums:
####we could do this with sweep() or mutate_all() or other ways, but using vegan:
combined_df_prop <- decostand(combined_df, method = "total", MARGIN = 2)
####Second, we want to ask how the proprortion for each species has changed across columns (samples).
####We do this by scaling everything to the max observed in each row.
####To do this WITHIN a dataset, we could just do (again, using vegan):
####eDNA Index between 0-1 made by straight adding reads across each decontaminated datatable
combined_df_index <- decostand(combined_df_prop, method = "max", MARGIN = 1)
#Output read counts
hash.key.updated.2 <- hash.key.updated[!duplicated(hash.key.updated$number), ]
combined_df$number <- rownames(combined_df)
combined_df %>%
left_join(hash.key.updated.2, by="number") %>%
dplyr::select(-number,-seq_number) -> combined_df
saveRDS(combined_df,file=here("decontam","Output_R","pre_occupancy_results_sum.taxonomy_tech_reps_summed_read_counts.RDS"))
write_csv(combined_df,here("decontam","Output_R","pre_occupancy_results_sum.taxonomy_tech_reps_summed_read_counts.csv"))
combined_df_index$number <- rownames(combined_df_index)
combined_df_index %>%
left_join(hash.key.updated.2, by="number") %>%
dplyr::select(-number,-seq_number) -> combined_df_index
saveRDS(combined_df_index,file=here("decontam","Output_R","pre_occupancy_results_sum.taxonomy_tech_reps_summed_eDNA_index.RDS"))
write_csv(combined_df_index,here("decontam","Output_csv","pre_occupancy_results_sum.taxonomy_tech_reps_summed_eDNA_index.csv"))
ASV.nested$Step5.tibble[[1]] %>%
mutate(Sample = sample) %>%
left_join(hash.key.updated) %>%
dplyr::group_by(number,Sample) %>%
dplyr::summarise(nReads=sum(nReads)) %>%
spread(., Sample, nReads) %>% #convert to wide data format
replace(is.na(.), 0)  -> barcode_1_post_df
barcode_1_post_df$number %>%  unique() -> barcode_1_post_df_taxa
metadata %>%
filter(., !(New_name %in% controls)) %>%
filter(.,!(New_name %in% colnames(barcode_1_post_df))) %>%
pull(New_name) %>%  unique()-> columns2add
barcode_1_post_df <- as.data.frame(barcode_1_post_df)
barcode_1_post_df %>%
tibble::add_column(!!!set_names(as.list(rep(NA, length(columns2add))),nm=columns2add)) %>%
replace(is.na(.), 0) %>%
dplyr::select(sort(tidyselect::peek_vars()))-> barcode_1_post_df
row.names(barcode_1_post_df) <- barcode_1_post_df$number
barcode_1_post_df %>% ungroup() -> barcode_1_post_df
total_kept_taxa <- barcode_1_post_df_taxa %>% unique()
if (rlang::is_empty(setdiff(total_kept_taxa,barcode_1_post_df_taxa))) {
barcode_1_post_df %>% ungroup() %>%
arrange(number) -> barcode_1_post_df
} else {
barcode_1_post_df %>% ungroup() %>%
add_row(number=setdiff(total_kept_taxa,barcode_1_post_df_taxa)) %>%
arrange(number) %>%
replace(is.na(.), 0) -> barcode_1_post_df
}
barcode_1_post_df <- as.data.frame(barcode_1_post_df)
row.names(barcode_1_post_df) <- barcode_1_post_df$number
barcode_1_post_df %>% ungroup() %>% dplyr::select(-number) -> barcode_1_post_df
barcode_1_post_df -> combined_df
####First, we want to create proportions by dividing by the rowsums:
####we could do this with sweep() or mutate_all() or other ways, but using vegan:
combined_df_prop <- decostand(combined_df, method = "total", MARGIN = 2)
####Second, we want to ask how the proprortion for each species has changed across columns (samples).
####We do this by scaling everything to the max observed in each row.
####To do this WITHIN a dataset, we could just do (again, using vegan):
####eDNA Index between 0-1 made by straight adding reads across each decontaminated datatable
combined_df_index <- decostand(combined_df_prop, method = "max", MARGIN = 1)
#Output read counts
hash.key.updated.2 <- hash.key.updated[!duplicated(hash.key.updated$number), ]
combined_df$number <- rownames(combined_df)
combined_df %>%
left_join(hash.key.updated.2, by="number") %>%
dplyr::select(-number,-seq_number) -> combined_df
saveRDS(combined_df,file=here("decontam","Output_R","post_occupancy_results_sum.taxonomy_tech_reps_summed_read_counts.RDS"))
write_csv(combined_df,here("decontam","Output_csv","post_occupancy_results_sum.taxonomy_tech_reps_summed_read_counts.csv"))
combined_df_index$number <- rownames(combined_df_index)
combined_df_index %>%
left_join(hash.key.updated.2, by="number") %>%
dplyr::select(-number,-seq_number) -> combined_df_index
saveRDS(combined_df_index,file=here("decontam","Output_R","post_occupancy_results_sum.taxonomy_tech_reps_summed_eDNA_index.RDS"))
write_csv(combined_df_index,here("decontam","Output_csv","post_occupancy_results_sum.taxonomy_tech_reps_summed_eDNA_index.csv"))
ASV.nested %>%
dplyr::select(Step3.tibble,Miseq_run) %>%
unnest(Step3.tibble) %>%
left_join(hash.key.updated) %>%
left_join(metadata, by=c("sample"="New_name")) %>%
dplyr::group_by(sum.taxonomy,Site) %>%
dplyr::summarise(nReads=sum(nReads)) %>%
spread(., Site, nReads) %>% #convert to wide data format
replace(is.na(.), 0)  -> pre_wide_reads
saveRDS(pre_wide_reads,file=here("decontam","Output_R","pre_occ_site_sum.taxonomy_reads_summed.RDS"))
write_csv(pre_wide_reads ,here("decontam","Output_R","pre_occ_site_sum.taxonomy_reads_summed.csv"))
ASV.nested %>%
dplyr::select(Step3.tibble,Miseq_run) %>%
unnest(Step3.tibble) %>%
left_join(hash.key.updated) %>%
left_join(metadata, by=c("sample"="New_name")) %>%
ungroup() %>%
group_by(Site, sum.taxonomy) %>%
summarise(meanreads = mean(nReads)) %>%
dplyr::group_by(Site) %>%
mutate (Tot = sum(meanreads),
Row.sums = meanreads / Tot) %>%
dplyr::group_by (sum.taxonomy) %>%
mutate (Colmax = max (Row.sums),
Normalized.reads = Row.sums / Colmax) %>%
ungroup() %>%
dplyr::select(Site,Normalized.reads, sum.taxonomy) %>%
spread(., Site, Normalized.reads) %>% #convert to wide data format
replace(is.na(.), 0)  -> pre_wide
saveRDS(pre_wide,file=here("decontam","Output_R","pre_occ_site_averaged_sum.taxonomy_e_index.RDS"))
write_csv(pre_wide,here("decontam","Output_R","pre_occ_site_averaged_sum.taxonomy_e_index.csv"))
ASV.nested %>%
dplyr::select(Step5.tibble) %>%
unnest(Step5.tibble) %>%
ungroup() %>%
dplyr::group_by(sum.taxonomy,Site) %>%
dplyr::summarise(nReads=sum(nReads)) %>%
spread(., Site, nReads) %>% #convert to wide data format
replace(is.na(.), 0)  -> post_wide_reads
saveRDS(post_wide_reads,file=here("decontam","Output_R","post_occ_site_sum.taxonomy_reads_summed.RDS"))
write_csv(post_wide_reads ,here("decontam","Output_R","post_occ_site_sum.taxonomy_reads_summed.csv"))
ASV.nested %>%
dplyr::select(Step5.tibble) %>%
unnest(Step5.tibble) %>%
ungroup() %>%
group_by(Site, sum.taxonomy) %>%
summarise(meanreads = mean(nReads)) %>%
dplyr::group_by(Site) %>%
mutate (Tot = sum(meanreads),
Row.sums = meanreads / Tot) %>%
dplyr::group_by (sum.taxonomy) %>%
mutate (Colmax = max(Row.sums),
Normalized.reads = Row.sums / Colmax) %>%
dplyr::select(Site,Normalized.reads, sum.taxonomy) %>%
spread(., Site, Normalized.reads) %>% #convert to wide data format
replace(is.na(.), 0)  -> post_wide
saveRDS(post_wide,file=here("decontam","Output_R","post_occ_site_averaged_sum.taxonomy_e_index.RDS"))
write_csv(post_wide,here("decontam","Output_R","post_occ_site_averaged_sum.taxonomy_e_index.csv"))
library(phyloseq)
library(wesanderson)
library(tidyverse)
library(vegan)
library(iNEXT)
library(Cairo)
library(multcomp)
library(multcompView)
library(treemapify)
library(brew)
library(RColorBrewer)
library(car)
library(VennDiagram)
library(here)
library(MASS)
library(scales)
library(gridExtra)
library(segmented)
post_occ_index <- readRDS(file=here("decontam","Output_R","post_occupancy_results_sum.taxonomy_tech_reps_summed_eDNA_index.RDS"))
colnames(post_occ_index) %>% str_replace_all(., "-",".") -> post_occ_index_names
colnames(post_occ_index) <-post_occ_index_names
post_occ_counts <- readRDS(file=here("decontam","Output_R","post_occupancy_results_sum.taxonomy_tech_reps_summed_read_counts.RDS"))
colnames(post_occ_counts) %>% str_replace_all(., "-",".") ->post_occ_counts_names
colnames(post_occ_counts) <-post_occ_counts_names
pre_index <- readRDS(file=here("decontam","Output_R","pre_occupancy_results_sum.taxonomy_tech_reps_summed_eDNA_index.RDS"))
colnames(pre_index) %>% str_replace_all(., "-",".") -> pre_index_names
colnames(pre_index) <-pre_index_names
pre_counts <- readRDS(file=here("decontam","Output_R","pre_occupancy_results_sum.taxonomy_tech_reps_summed_read_counts.RDS"))
colnames(pre_counts) %>% str_replace_all(., "-",".") -> pre_counts_names
colnames(pre_counts) <-pre_counts_names
ASV.nested.mpa <- readRDS(file=here("decontam","ASV.nested_final.RDS"))
#Metadata
input_meta_path <- "data/mpa_metadata_02042020.txt"
metadata <- read.table(here(input_meta_path), header = 1, sep = "\t", stringsAsFactors = F)
metadata %>%
dplyr::select(-Seq_number) %>%
rename(Seq_number=New_name) %>%
mutate(., Seq_number= str_replace_all(Seq_number, "-","."))-> metadata
#Create list of Taylor and MPA Samples
metadata %>%
filter(Site=="Taylor") %>%
dplyr::select(Seq_number) -> Taylor_samples
Taylor_samples <-  Taylor_samples$Seq_number
#Post Occ
##eDNA Index
physeq_obj.occ <- convert_anacapa_to_phyloseq(post_occ_index, metadata)
#Reads
physeq_obj.occ_reads <- convert_anacapa_to_phyloseq(post_occ_counts, metadata)
#eDNA Index Pre Occ
physeq_obj.pre <- convert_anacapa_to_phyloseq(pre_index, metadata)
#eDNA Index Post OCC
physeq_obj.pre_reads <- convert_anacapa_to_phyloseq(pre_counts, metadata)
#removed Lab Contaminant ASVs
badTaxa = c("","Unassigned",
"NA",
"Eukaryota;Chordata;;NA;;;",
"Eukaryota;Chordata;Actinopteri;Salmoniformes;Salmonidae;Salmo;Salmo salar",
"Eukaryota;Chordata;Mammalia;Primates;Hominidae;Homo;Homo sapiens",
"Eukaryota;Chordata;Mammalia;Artiodactyla;Bovidae;Bos;Bos taurus",
"Eukaryota;Chordata;Actinopteri;Salmoniformes;Salmonidae;Salmo;",
"Eukaryota;Chordata;Actinopteri;Cypriniformes;Cyprinidae;Ctenopharyngodon;Ctenopharyngodon idella",
"Eukaryota;Chordata;Actinopteri;Salmoniformes;Salmonidae;Oncorhynchus;",                                  "Eukaryota;Chordata;Actinopteri;Salmoniformes;Salmonidae;Oncorhynchus;Oncorhynchus tshawytscha")
goodTaxa_1 <- setdiff(taxa_names(physeq_obj.occ), badTaxa)
goodTaxa_2 <- setdiff(taxa_names(physeq_obj.occ_reads), badTaxa)
goodTaxa_3 <- setdiff(taxa_names(physeq_obj.pre), badTaxa)
goodTaxa_4 <- setdiff(taxa_names(physeq_obj.pre_reads), badTaxa)
physeq_obj.occ <- prune_taxa(goodTaxa_1, physeq_obj.occ)
physeq_obj.occ_reads <- prune_taxa(goodTaxa_2, physeq_obj.occ_reads)
physeq_obj.pre <- prune_taxa(goodTaxa_3, physeq_obj.pre)
physeq_obj.pre_reads <- prune_taxa(goodTaxa_4, physeq_obj.pre_reads)
physeq_obj.occ <- subset_samples(physeq_obj.occ, Site !="Taylor")
physeq_obj.occ_reads <- subset_samples(physeq_obj.occ_reads, Site !="Taylor")
physeq_obj.pre <- subset_samples(physeq_obj.pre, Site !="Taylor")
physeq_obj.pre_reads <- subset_samples(physeq_obj.pre_reads, Site !="Taylor")
physeq_obj.occ = filter_taxa(physeq_obj.occ, function(x) mean(x) > 0, TRUE)
physeq_obj.occ_reads = filter_taxa(physeq_obj.occ_reads, function(x) mean(x) > 0, TRUE)
physeq_obj.pre = filter_taxa(physeq_obj.pre, function(x) mean(x) > 0, TRUE)
physeq_obj.pre_reads = filter_taxa(physeq_obj.pre_reads, function(x) mean(x) > 0, TRUE)
physeq_obj.pre
physeq_obj.occ
ASV.nested %>%
dplyr::select(Step5.tibble) %>%
unnest(Step5.tibble) %>%
filter(., !sample %in% Taylor_samples) %>%
filter(., nReads >0) %>%  dplyr::select(seq_number) %>% unique() %>% dim() -> unique_ASVs
unique_ASVs[[1]]
ASV.nested %>%
dplyr::select(Step5.tibble) %>%
unnest(Step5.tibble) %>%
filter(., !sample %in% Taylor_samples)
ASV.nested %>%
dplyr::select(Step5.tibble) %>%
unnest(Step5.tibble) %>%
filter(., !sample %in% Taylor_samples) %>%
filter(., nReads >0) %>%  dplyr::select(seq_number) %>% unique() %>% dim() -> unique_ASVs
unique_ASVs[[1]]
sample_sums(physeq_obj.occ_reads) %>%
as.data.frame() %>% summarise(., total_reads=sum(.))
get_taxa_unique(physeq_obj.occ_reads,"Species") %>% as.data.frame %>% rename(., Species=.) %>% arrange(Species) %>%  kable()
Phylum <- length(get_taxa_unique(physeq_obj.occ_reads, "Phylum"))
Phylum <- as.data.frame(Phylum)
Class <- length(get_taxa_unique(physeq_obj.occ_reads, "Class"))
Class <- as.data.frame(Class)
Order <- length(get_taxa_unique(physeq_obj.occ_reads, "Order"))-2
Order <- as.data.frame(Order)
Family <- length(get_taxa_unique(physeq_obj.occ_reads, "Family"))
Family <- as.data.frame(Family)
Genus <- length(get_taxa_unique(physeq_obj.occ_reads, "Genus"))-1
Genus <- as.data.frame(Genus)
Species <- length(get_taxa_unique(physeq_obj.occ_reads, "Species"))-1
Species <- as.data.frame(Species)
table_step3 <- bind_cols(Phylum,Class,Order,Family,Genus,Species)
rownames(table_step3) <- "Unique"
table_step3
get_taxa_unique(physeq_obj.occ,"Species") -> eDNA_step2_species
get_taxa_unique(physeq_obj.pre,"Species") -> eDNA_step1_species
setdiff(eDNA_step1_species,eDNA_step2_species) %>%  sort()
5/13
functional_traits_species_only %>%
filter(Species_found.post !="Common_species")
functional_traits_species_only %>%
filter(Species_found.post !="Common_species") %>%
dplyr::select(Species)
functional_traits_species_only %>%
filter(Species_found.post !="Common_species") %>%
group_by(Habitat) %>%
tally()
functional_traits_species_only %>%
filter(Species_found.post !="Common_species") %>%
filter(Habitat !="rockyreef") %>%
dplyr::select(Species)
# NMDS ordination
ord_j <- ordinate(physeq_obj.occ, method = "NMDS", distance = d_carn_j)
ord_j
nps_all_unique
nps_all_unique %>%  sort()
nps_all_unique
#Species Only Found by NPS Compared to Post Occupancy eDNA Data
setdiff(nps_all_unique,get_taxa_unique(physeq_obj.occ,"Species"))
eDNA_step2_species
